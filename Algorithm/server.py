from flask import Flask
from flask_restx import Api, Resource, fields
from flask_cors import CORS
import torch
import os
from transformers import (
    BertTokenizer,
    BertModel,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding,
)
from torch import nn
import torch
from datasets import load_dataset
import numpy as np
from sklearn.metrics import accuracy_score, mean_squared_error
import matplotlib.pyplot as plt
from transformers.modeling_outputs import ModelOutput
from typing import Optional, Tuple
from collections import Counter
from transformers import EarlyStoppingCallback, get_scheduler

import random
import re
import nlpaug.augmenter.word as naw

# from transformers import BertTokenizer, BertModel, TrainingArguments, Trainer, DataCollatorWithPadding
# from torch import nn
# import torch
# from datasets import load_dataset
# import numpy as np
# from sklearn.metrics import accuracy_score, mean_squared_error
# import matplotlib.pyplot as plt
# from transformers.modeling_outputs import ModelOutput
# from typing import Optional, Tuple
# from collections import Counter
# from transformers import EarlyStoppingCallback, get_scheduler

# import random
# import re
# import nlpaug.augmenter.word as naw

# emotion_synonyms = {
#     "å¼€å¿ƒ": ["é«˜å…´", "æ„‰å¿«", "å¿«ä¹", "å…´å¥‹"],
#     "éš¾è¿‡": ["ä¼¤å¿ƒ", "æ‚²ä¼¤", "æ²®ä¸§", "å¤±è½"],
#     "ç”Ÿæ°”": ["æ„¤æ€’", "æ¼ç«", "æ°”æ„¤", "æ¿€åŠ¨"],
#     "å®³æ€•": ["ææƒ§", "æ‹…å¿ƒ", "å®³æ€•", "æƒŠæ"],
#     "å–œæ¬¢": ["å–œçˆ±", "çˆ±", "é’Ÿæ„", "åçˆ±"],
#     "è®¨åŒ": ["åŒæ¶", "å«Œå¼ƒ", "åæ„Ÿ", "ä¸å–œæ¬¢"]
# }


# # ä½¿ç”¨ä¸ç®€åŒ–çš„æ¨¡å‹ï¼Œå¹¶é™ä½æ¨¡å‹å¤æ‚åº¦
# class SimplifiedBertForEmotionMultiTask(nn.Module):
#     def __init__(self, model_name, num_labels=5, dropout_rate=0.5):
#         super().__init__()
#         self.bert = BertModel.from_pretrained(model_name)
#         self.dropout = nn.Dropout(dropout_rate)  # ä¿ç•™è¾ƒå¼ºçš„dropout
#         self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)
#         self.regressor = nn.Linear(self.bert.config.hidden_size, 1)

#         # åˆå§‹åŒ–æƒé‡
#         nn.init.xavier_normal_(self.classifier.weight)
#         nn.init.xavier_normal_(self.regressor.weight)

#     def forward(self, input_ids, attention_mask=None, labels=None, labels_intensity=None):
#         outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
#         cls_output = outputs.last_hidden_state[:, 0]  # ä½¿ç”¨CLSå‘é‡
#         cls_output = self.dropout(cls_output)  # æ·»åŠ dropout

#         logits = self.classifier(cls_output)
#         intensity = self.regressor(cls_output).squeeze(-1)

#         loss = None
#         if labels is not None and labels_intensity is not None:
#             loss_fct_cls = nn.CrossEntropyLoss()
#             loss_fct_reg = nn.MSELoss()
#             # å¹³è¡¡åˆ†ç±»å’Œå›å½’ä»»åŠ¡æƒé‡
#             loss = 0.8 * loss_fct_cls(logits, labels) + 0.2 * loss_fct_reg(intensity, labels_intensity)

#         return {"loss": loss, "logits": logits, "intensity": intensity}


# # æ”¹è¿›çš„æ•°æ®å¢å¼ºå‡½æ•°ï¼šä½¿ç”¨å¤šç§å¢å¼ºæŠ€æœ¯
# def augment_emotion_text(text, prob=0.3):
#     """
#     å¯¹æ–‡æœ¬è¿›è¡Œæƒ…ç»ªåŒä¹‰è¯æ›¿æ¢å¢å¼ºã€‚
#     :param text: åŸå§‹æ–‡æœ¬
#     :param prob: æ¯ä¸ªè¯è¢«æ›¿æ¢çš„æ¦‚ç‡
#     :return: å¢å¼ºåçš„æ–‡æœ¬
#     """
#     # ç­–ç•¥1: åŒä¹‰è¯æ›¿æ¢
#     for word, synonyms in emotion_synonyms.items():
#         if word in text and random.random() < prob:
#             new_word = random.choice([s for s in synonyms if s != word])
#             text = re.sub(word, new_word, text)

#     # ç­–ç•¥2: éšæœºåˆ é™¤ä¸€äº›éå…³é”®è¯ï¼ˆä¿æŒæƒ…ç»ªè¯ï¼‰
#     if random.random() < prob:
#         words = text.split()
#         emotion_words = [word for word, _ in emotion_synonyms.items()]
#         all_emotion_words = emotion_words + [syn for synonyms in emotion_synonyms.values() for syn in synonyms]

#         # ç¡®ä¿ä¸åˆ é™¤æƒ…ç»ªè¯
#         filtered_words = []
#         for word in words:
#             if word in all_emotion_words or random.random() > 0.2:  # 20%æ¦‚ç‡åˆ é™¤éæƒ…ç»ªè¯
#                 filtered_words.append(word)
#         text = ' '.join(filtered_words) if filtered_words else text

#     return text

# # âœ… Step 1: åŠ è½½ä¸­æ–‡ BERT æ¨¡å‹å’Œ tokenizer
# MODEL_PATH = "bert-base-chinese"
# tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)
# # ä½¿ç”¨ç®€åŒ–åçš„æ¨¡å‹
# model = SimplifiedBertForEmotionMultiTask(MODEL_PATH)

# # âœ… Step 2: åŠ è½½å’Œåˆ‡åˆ† sepidmnorozy/Chinese_sentiment
# dataset = load_dataset("sepidmnorozy/Chinese_sentiment")
# train_dataset = dataset["train"]
# eval_dataset = dataset["test"]

# # æ‰“å°æ•°æ®é›†åˆ†å¸ƒä¿¡æ¯
# print("è®­ç»ƒé›†å¤§å°:", len(train_dataset))
# print("æµ‹è¯•é›†å¤§å°:", len(eval_dataset))
# print("æ ‡ç­¾åˆ†å¸ƒ(è®­ç»ƒé›†):", Counter(train_dataset["label"]))
# print("æ ‡ç­¾åˆ†å¸ƒ(æµ‹è¯•é›†):", Counter(eval_dataset["label"]))

# # âœ… Step 3: æ•°æ®é¢„å¤„ç†
# def preprocess(example):
#     original_text = example["text"]
#     # æ¦‚ç‡å¢å¼º
#     aug_text = augment_emotion_text(original_text)
#     # åªä¿ç•™æƒ…ç»ªè¯
#     tokens = tokenizer(aug_text, padding="max_length", truncation=True, max_length=256)
#     tokens["labels"] = int(example["label"])
#     tokens["labels_intensity"] = float(example["label"]) / 2.0  # å°†æ ‡ç­¾è½¬æ¢ä¸º0-1èŒƒå›´
#     return tokens

# train_dataset = train_dataset.map(preprocess)
# eval_dataset = eval_dataset.map(preprocess)
# train_dataset.set_format(type="torch", columns=["input_ids", "attention_mask", "labels", "labels_intensity"])
# eval_dataset.set_format(type="torch", columns=["input_ids", "attention_mask", "labels", "labels_intensity"])


# # âœ… Step 4: å¤šä»»åŠ¡æ¨¡å‹å®šä¹‰ï¼ˆä½¿ç”¨æ›´å¼ºçš„æ­£åˆ™åŒ–ï¼‰
class BertForEmotionMultiTask(nn.Module):
    def __init__(self, model_name, num_labels=2, dropout_rate=0.5):
        super().__init__()
        self.bert = BertModel.from_pretrained(model_name)
        self.dropout = nn.Dropout(dropout_rate)  # æ›´å¼ºçš„dropout
        # æ­£åˆ™åŒ–: åŠ å…¥LayerNorm
        self.layer_norm = nn.LayerNorm(self.bert.config.hidden_size)
        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)
        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)

        # åˆå§‹åŒ–æƒé‡
        nn.init.xavier_normal_(self.classifier.weight)
        nn.init.xavier_normal_(self.regressor.weight)

    def forward(
        self, input_ids, attention_mask=None, labels=None, labels_intensity=None
    ):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        cls_output = outputs.last_hidden_state[:, 0]  # ç”¨CLSå‘é‡
        cls_output = self.layer_norm(cls_output)  # æ·»åŠ LayerNorm
        cls_output = self.dropout(cls_output)  # æ›´å¼ºçš„dropout

        logits = self.classifier(cls_output)
        intensity = self.regressor(cls_output).squeeze(-1)

        loss = None
        if labels is not None and labels_intensity is not None:
            loss_fct_cls = nn.CrossEntropyLoss()
            loss_fct_reg = nn.MSELoss()
            # å¹³è¡¡åˆ†ç±»å’Œå›å½’ä»»åŠ¡æƒé‡
            loss = 0.8 * loss_fct_cls(logits, labels) + 0.2 * loss_fct_reg(
                intensity, labels_intensity
            )

            # æ·»åŠ L2æ­£åˆ™åŒ– (æƒé‡è¡°å‡åœ¨ä¼˜åŒ–å™¨ä¸­å¤„ç†)
        return {"loss": loss, "logits": logits, "intensity": intensity}


# model = BertForEmotionMultiTask(MODEL_PATH)

# # âœ… Step 5: è‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡
# def compute_metrics(pred):
#     logits, intensity_preds = pred.predictions
#     labels, intensity_labels = pred.label_ids

#     preds = np.argmax(logits, axis=1)
#     print("é¢„æµ‹åˆ†å¸ƒï¼š", Counter(preds))  # è§‚å¯Ÿæ˜¯å¦åªé¢„æµ‹æŸä¸€ç±»

#     acc = accuracy_score(labels, np.argmax(logits, axis=1))
#     mse = mean_squared_error(intensity_labels, intensity_preds)
#     return {"accuracy": acc, "mse": mse}

# # âœ… Step 6: é…ç½®è®­ç»ƒå‚æ•°ï¼ˆåŠ å…¥æ—©åœå’Œå­¦ä¹ ç‡è°ƒåº¦ï¼‰
# training_args = TrainingArguments(
#     output_dir="./results",
#     eval_strategy="epoch",
#     save_strategy="epoch",
#     logging_strategy="epoch",
#     num_train_epochs=20,  # è®¾ç½®æ›´é•¿çš„è½®æ¬¡ï¼Œè®©æ—©åœç”Ÿæ•ˆ
#     per_device_train_batch_size=16,
#     per_device_eval_batch_size=16,
#     learning_rate=2e-5,  # ç¨å¾®æé«˜å­¦ä¹ ç‡
#     weight_decay=0.05,   # å¢åŠ æƒé‡è¡°å‡å‡è½»è¿‡æ‹Ÿåˆ
#     load_best_model_at_end=True,
#     metric_for_best_model="accuracy",
#     greater_is_better=True,
#     save_total_limit=3,  # ä¿å­˜æœ€ä½³çš„å‡ ä¸ªæ¨¡å‹
#     fp16=True,
#     warmup_ratio=0.1,    # å­¦ä¹ ç‡é¢„çƒ­
#     max_grad_norm=1.0,   # æ¢¯åº¦å‰ªè£
#     lr_scheduler_type="cosine",  # ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
# )

# # å¢åŠ æ—©åœå›è°ƒ
# early_stopping = EarlyStoppingCallback(
#     early_stopping_patience=3,  # è¿ç»­3æ¬¡éªŒè¯é›†æ€§èƒ½æ²¡æé«˜å°±åœæ­¢
#     early_stopping_threshold=0.001  # æœ€å°æå‡é˜ˆå€¼
# )

# trainer = Trainer(
#     model=model,
#     args=training_args,
#     train_dataset=train_dataset,
#     eval_dataset=eval_dataset,
#     tokenizer=tokenizer,
#     data_collator=DataCollatorWithPadding(tokenizer),
#     compute_metrics=compute_metrics,
#     callbacks=[early_stopping],  # æ·»åŠ æ—©åœå›è°ƒ
# )

# # è®­ç»ƒå‰æŸ¥çœ‹æ•°æ®åˆ†å¸ƒ
# print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
# print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(eval_dataset)}")

# # å¼€å§‹è®­ç»ƒ
# train_result = trainer.train()
# print(f"è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯é›†å‡†ç¡®ç‡: {trainer.state.best_metric}")

# # âœ… Step 7: ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹å›¾
# logs = trainer.state.log_history
# train_loss = [log["loss"] for log in logs if "loss" in log and "epoch" in log]
# eval_acc = [log["eval_accuracy"] for log in logs if "eval_accuracy" in log]
# eval_mse = [log["eval_mse"] for log in logs if "eval_mse" in log]
# epochs = [log["epoch"] for log in logs if "epoch" in log and ("loss" in log or "eval_accuracy" in log)]

# plt.figure(figsize=(15, 10))

# # è®­ç»ƒæŸå¤±
# plt.subplot(2, 2, 1)
# plt.plot(epochs[:len(train_loss)], train_loss, marker='o')
# plt.title("Training Loss")
# plt.xlabel("Epoch")
# plt.ylabel("Loss")
# plt.grid(True)

# # éªŒè¯å‡†ç¡®ç‡
# plt.subplot(2, 2, 2)
# plt.plot(epochs[-len(eval_acc):], eval_acc, marker='o', color='green')
# plt.title("Validation Accuracy")
# plt.xlabel("Epoch")
# plt.ylabel("Accuracy")
# plt.grid(True)

# # éªŒè¯MSE
# plt.subplot(2, 2, 3)
# plt.plot(epochs[-len(eval_mse):], eval_mse, marker='o', color='red')
# plt.title("Validation Intensity MSE")
# plt.xlabel("Epoch")
# plt.ylabel("MSE")
# plt.grid(True)

# # å¯¹æ¯”è®­ç»ƒæŸå¤±å’ŒéªŒè¯å‡†ç¡®ç‡
# plt.subplot(2, 2, 4)
# ax1 = plt.gca()
# ax1.plot(epochs[:len(train_loss)], train_loss, marker='o', color='blue', label='Train Loss')
# ax1.set_xlabel('Epoch')
# ax1.set_ylabel('Loss', color='blue')

# ax2 = ax1.twinx()
# ax2.plot(epochs[-len(eval_acc):], eval_acc, marker='o', color='green', label='Val Accuracy')
# ax2.set_ylabel('Accuracy', color='green')

# plt.title("Loss vs Accuracy")
# lines1, labels1 = ax1.get_legend_handles_labels()
# lines2, labels2 = ax2.get_legend_handles_labels()
# ax1.legend(lines1 + lines2, labels1 + labels2, loc='best')
# plt.grid(True)

# plt.tight_layout()
# plt.show()

# torch.save(model.state_dict(), './Chinese_sentiment_model/pytorch_model.bin')
# tokenizer.save_pretrained('./Chinese_sentiment_model')

#   å¯åŠ¨æ¨¡å‹æœåŠ¡ http
# Create Flask app
app = Flask(__name__)
api = Api(
    app,
    version="1.0",
    title="Chinese Emotion Analysis API",
    description="API for analyzing emotions in Chinese text",
)

# è§£å†³è·¨åŸŸé—®é¢˜
CORS(app, resources={r"/*": {"origins": "*"}})

# Define namespaces
ns = api.namespace("emotion", description="Emotion Analysis Operations")

# Define request/response models for Swagger documentation
emotion_request = api.model(
    "EmotionRequest",
    {"text": fields.String(required=True, description="Chinese text to analyze")},
)

emotion_response = api.model(
    "EmotionResponse",
    {
        "emotion": fields.String(description="Predicted emotion category"),
        "intensity": fields.Float(description="Predicted emotion intensity (0-1)"),
        "probabilities": fields.Raw(
            description="Probability distribution for each emotion class"
        ),
    },
)

# Load the model and tokenizer
model_path = "./Chinese_sentiment_model"
tokenizer = BertTokenizer.from_pretrained(model_path)

# Load the model architecture
model = BertForEmotionMultiTask("bert-base-chinese")
# Load the trained weights
model.load_state_dict(
    torch.load(
        os.path.join(model_path, "pytorch_model.bin"), map_location=torch.device("cpu")
    )
)
model.eval()  # Set

# Define emotion labels
# 0æ˜¯è´Ÿé¢ã€1æ˜¯æ­£é¢
emotion_labels = [0,1]  # Adjust based on your model's actual classes


# Define the endpoint for emotion analysis
@ns.route("/analyze")
class EmotionAnalysis(Resource):
    @ns.expect(emotion_request)
    @ns.marshal_with(emotion_response)
    def post(self):
        """Analyze emotion in the provided Chinese text"""
        # Get text from request
        text = api.payload["text"]

        # Tokenize the input
        inputs = tokenizer(
            text, return_tensors="pt", padding=True, truncation=True, max_length=256
        )
        inputs.pop("token_type_ids", None)
        # Get prediction
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs["logits"]
            intensity = outputs["intensity"].item()

            # Get probabilities using softmax
            probabilities = torch.nn.functional.softmax(logits, dim=1)[0].tolist()
            predicted_class = torch.argmax(logits, dim=1).item()
        
        # Return prediction results
        return {
            "emotion": emotion_labels[predicted_class],
            "intensity": intensity,
            "probabilities": {
                emotion_labels[i]: prob for i, prob in enumerate(probabilities)
            },
        }


# Run the Flask app
if __name__ == "__main__":
    # Import missing dependencies at the top that were commented out
    # Create a sample input and call the model once before starting the server
    sample_text = "æˆ‘ä»Šå¤©å¾ˆå¼€å¿ƒ"
    sample_inputs = tokenizer(
        sample_text, return_tensors="pt", padding=True, truncation=True, max_length=256
    )
    with torch.no_grad():
        # Remove token_type_ids from inputs as the model does not expect it
        label_map = {0: "è´Ÿé¢", 1: "æ­£é¢"}
        sample_inputs.pop("token_type_ids", None)
        result = model(**sample_inputs)
        logits = result["logits"]
        intensity = result["intensity"]
        preds = torch.argmax(logits, dim=1).cpu().numpy()[0]
        intensities = intensity.cpu().numpy()[0]
        print(f"TEST ğŸ‘‰ è¾“å…¥æ–‡æœ¬ï¼š{sample_text}")
        print(f"TEST ğŸ‘‰ æƒ…ç»ªç±»åˆ«ï¼š{label_map[preds]}ï¼ˆlabel={preds}ï¼‰ï¼Œå¼ºåº¦ï¼š{intensities:.4f}")

    # Run the server
    app.run(host="0.0.0.0", port=5000, debug=False)
