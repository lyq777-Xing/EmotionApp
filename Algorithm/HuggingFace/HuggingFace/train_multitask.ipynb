{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "My favourite food is anything I didn't have to cook myself.\n",
      "Labels: ['neutral']\n",
      "Five-class label: neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 43410/43410 [00:06<00:00, 6642.34 examples/s]\n",
      "Map: 100%|██████████| 5426/5426 [00:00<00:00, 6428.33 examples/s]\n",
      "Map: 100%|██████████| 5427/5427 [00:00<00:00, 6440.90 examples/s]\n",
      "C:\\Users\\lyq\\AppData\\Local\\Temp\\ipykernel_12648\\13127810.py:188: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:777\u001b[39m, in \u001b[36mBatchEncoding.convert_to_tensors\u001b[39m\u001b[34m(self, tensor_type, prepend_batch_axis)\u001b[39m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[32m--> \u001b[39m\u001b[32m777\u001b[39m     tensor = \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[32m    780\u001b[39m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[32m    781\u001b[39m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[32m    782\u001b[39m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[32m    783\u001b[39m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[32m    784\u001b[39m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:739\u001b[39m, in \u001b[36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[39m\u001b[34m(value, dtype)\u001b[39m\n\u001b[32m    738\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.from_numpy(np.array(value))\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: expected sequence of length 1 at dim 1 (got 2)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 200\u001b[39m\n\u001b[32m    197\u001b[39m     trainer.train()\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 197\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    186\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (logits.detach().cpu().numpy(), preds.detach().cpu().numpy()), {\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m: labels.cpu().numpy(), \u001b[33m\"\u001b[39m\u001b[33mintensities\u001b[39m\u001b[33m\"\u001b[39m: intensities.cpu().numpy()}\n\u001b[32m    188\u001b[39m trainer = CustomTrainer(\n\u001b[32m    189\u001b[39m     model=model,\n\u001b[32m    190\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m     compute_metrics=compute_metrics,\n\u001b[32m    195\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\transformers\\trainer.py:2508\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2506\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2507\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2508\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2509\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[32m   2510\u001b[39m     step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\transformers\\trainer.py:5224\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5222\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5223\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5224\u001b[39m         batch_samples += [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m   5225\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5226\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\accelerate\\data_loader.py:566\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     current_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\transformers\\data\\data_collator.py:272\u001b[39m, in \u001b[36mDataCollatorWithPadding.__call__\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     batch = \u001b[43mpad_without_fast_tokenizer_warning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[32m    281\u001b[39m         batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] = batch[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\transformers\\data\\data_collator.py:67\u001b[39m, in \u001b[36mpad_without_fast_tokenizer_warning\u001b[39m\u001b[34m(tokenizer, *pad_args, **pad_kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m tokenizer.deprecation_warnings[\u001b[33m\"\u001b[39m\u001b[33mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     padded = \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpad_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpad_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Restore the state of the warning.\u001b[39;00m\n\u001b[32m     70\u001b[39m     tokenizer.deprecation_warnings[\u001b[33m\"\u001b[39m\u001b[33mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[33m\"\u001b[39m] = warning_state\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3407\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.pad\u001b[39m\u001b[34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[39m\n\u001b[32m   3404\u001b[39m             batch_outputs[key] = []\n\u001b[32m   3405\u001b[39m         batch_outputs[key].append(value)\n\u001b[32m-> \u001b[39m\u001b[32m3407\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:241\u001b[39m, in \u001b[36mBatchEncoding.__init__\u001b[39m\u001b[34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[39m\n\u001b[32m    237\u001b[39m     n_sequences = encoding[\u001b[32m0\u001b[39m].n_sequences\n\u001b[32m    239\u001b[39m \u001b[38;5;28mself\u001b[39m._n_sequences = n_sequences\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\HuggingFace\\hf\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:793\u001b[39m, in \u001b[36mBatchEncoding.convert_to_tensors\u001b[39m\u001b[34m(self, tensor_type, prepend_batch_axis)\u001b[39m\n\u001b[32m    788\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33moverflowing_tokens\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    789\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    790\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    791\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    792\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    794\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    795\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpadding=True\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtruncation=True\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    796\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    797\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m expected).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    798\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "class MultiTaskEmotionModel(nn.Module):\n",
    "    def __init__(self, model_name=\"bert-base-chinese\", num_labels=5):\n",
    "        super().__init__()\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        hidden_size = self.config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, num_labels)\n",
    "        )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()  # output range: 0 ~ 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, intensities=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.last_hidden_state[:, 0]\n",
    "\n",
    "        logits = self.classifier(pooled)\n",
    "        intensity_pred = self.regressor(pooled).squeeze(-1)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None and intensities is not None:\n",
    "            loss_cls = nn.CrossEntropyLoss()(logits, labels)\n",
    "            loss_reg = nn.MSELoss()(intensity_pred, intensities)\n",
    "            loss = loss_cls + loss_reg\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"logits\": logits,\n",
    "            \"intensity\": intensity_pred\n",
    "        }\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, intensity_preds = eval_pred.predictions\n",
    "    logits = logits[0] if isinstance(logits, tuple) else logits\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    labels = eval_pred.label_ids[\"labels\"]\n",
    "    intensities = eval_pred.label_ids[\"intensities\"]\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    mse = mean_squared_error(intensities, intensity_preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"mse\": mse}\n",
    "\n",
    "def tokenize(example, tokenizer):\n",
    "    # print(example)\n",
    "    result = tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    result[\"labels\"] = example[\"labels\"]\n",
    "    result[\"intensities\"] = example[\"five_class_label\"]\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def load_data(tokenizer):\n",
    "    # # 示例数据加载（你可以换成自己的）\n",
    "    # raw = load_dataset(\"go_emotions\", \"simplified\")  # or load custom dataset\n",
    "    # # raw = raw.remove_columns([\"id\", \"comments\", \"emotion\"])\n",
    "\n",
    "    # # 模拟强度值（真实使用你自己的数据）\n",
    "    # def add_intensity(example):\n",
    "    #     example[\"intensities\"] = np.random.uniform(0.5, 1.0) if example[\"labels\"] in [3,4] else np.random.uniform(0.0, 0.5)\n",
    "    #     return example\n",
    "\n",
    "    # raw = raw.map(add_intensity)\n",
    "    # return raw.map(lambda x: tokenize(x, tokenizer), batched=True)\n",
    "    from datasets import load_dataset\n",
    "    from collections import Counter\n",
    "\n",
    "    # 加载数据\n",
    "    dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "\n",
    "    # 五类情绪映射\n",
    "    five_class_mapping = {\n",
    "        'anger': 0, 'disgust': 0, 'fear': 0, 'sadness': 0,\n",
    "        'annoyance': 1, 'disappointment': 1, 'embarrassment': 1, 'grief': 1, 'nervousness': 1,\n",
    "        'neutral': 2, 'confusion': 2, 'curiosity': 2, 'realization': 2, 'desire': 2,\n",
    "        'approval': 3, 'love': 3, 'joy': 3, 'optimism': 3,\n",
    "        'admiration': 4, 'excitement': 4, 'gratitude': 4, 'pride': 4, 'relief': 4\n",
    "    }\n",
    "\n",
    "    id2label = ['very negative', 'negative', 'neutral', 'positive', 'very positive']\n",
    "    label2id = {v: k for k, v in enumerate(id2label)}\n",
    "\n",
    "    label_names = dataset['train'].features['labels'].feature.names\n",
    "\n",
    "    # 多标签情感 → 单个五类情绪映射\n",
    "    def map_emotion(example):\n",
    "        label_ids = example['labels']\n",
    "        if not label_ids:\n",
    "            return {'five_class_label': 2}  # 若无情绪标签则为 neutral\n",
    "\n",
    "        # 将所有原始标签映射为五类\n",
    "        five_class_votes = []\n",
    "        for i in label_ids:\n",
    "            emotion = label_names[i]\n",
    "            if emotion in five_class_mapping:\n",
    "                five_class_votes.append(five_class_mapping[emotion])\n",
    "        \n",
    "        # 若所有原始标签都不在映射表，设为 neutral\n",
    "        if not five_class_votes:\n",
    "            return {'five_class_label': 2}\n",
    "\n",
    "        # 选择出现次数最多的五类标签作为最终 label（也可选最“极端”的 max/min）\n",
    "        count = Counter(five_class_votes)\n",
    "        most_common = count.most_common(1)[0][0]\n",
    "        return {'five_class_label': most_common}\n",
    "\n",
    "    \n",
    "\n",
    "    # 应用映射\n",
    "    for split in dataset.keys():\n",
    "        dataset[split] = dataset[split].map(map_emotion)\n",
    "\n",
    "    # 示例打印\n",
    "    print(\"Example:\")\n",
    "    print(dataset['train'][0]['text'])\n",
    "    print(\"Labels:\", [label_names[i] for i in dataset['train'][0]['labels']])\n",
    "    print(\"Five-class label:\", id2label[dataset['train'][0]['five_class_label']])\n",
    "    return dataset.map(lambda x: tokenize(x, tokenizer), batched=True)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_model_path = \"./go_emotions_model_1\"  # 预训练模型路径\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "    raw_dataset = load_data(tokenizer)\n",
    "\n",
    "    train_dataset = raw_dataset[\"train\"]\n",
    "    val_dataset = raw_dataset[\"validation\"]\n",
    "\n",
    "    # 初始化多任务模型（不加载原分类头）\n",
    "    model = MultiTaskEmotionModel(model_name=base_model_path)\n",
    "\n",
    "    # 从旧模型中加载 encoder 权重\n",
    "    pretrained = AutoModel.from_pretrained(base_model_path)\n",
    "    model.bert.load_state_dict(pretrained.state_dict())\n",
    "\n",
    "    # 定义 Trainer 所需 TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./multitask_results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    # HuggingFace 的 Trainer 默认不支持多输出，我们需要用 wrapper\n",
    "    class CustomTrainer(Trainer):\n",
    "        def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            labels = inputs.pop(\"labels\")\n",
    "            intensities = inputs.pop(\"intensities\")\n",
    "            outputs = model(**inputs, labels=labels, intensities=intensities)\n",
    "            loss = outputs[\"loss\"]\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "        def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "            labels = inputs[\"labels\"]\n",
    "            intensities = inputs[\"intensities\"]\n",
    "            inputs = {k: v for k, v in inputs.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            logits = outputs[\"logits\"]\n",
    "            preds = outputs[\"intensity\"]\n",
    "            return None, (logits.detach().cpu().numpy(), preds.detach().cpu().numpy()), {\"labels\": labels.cpu().numpy(), \"intensities\": intensities.cpu().numpy()}\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
