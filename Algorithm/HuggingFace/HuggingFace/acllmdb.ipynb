{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers  import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6\n",
      "Using device: cuda\n",
      "Using device: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#确认GPU是否可用，如果不可用则使用CPU\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device=torch.device('cpu')\n",
    "print(torch.version.cuda)  # 例如 11.8\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Using device: {torch.cuda.is_available()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Path Exists: True\n",
      "Pos Path Exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_dir = \"../aclImdb/train\"\n",
    "print(\"Train Path Exists:\", os.path.exists(train_dir))\n",
    "print(\"Pos Path Exists:\", os.path.exists(os.path.join(train_dir, \"pos\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [02:47<00:00, 148.92 examples/s]\n",
      "Map: 100%|██████████| 25000/25000 [02:35<00:00, 161.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 定义路径\n",
    "train_dir = \"../aclImdb/train\"\n",
    "test_dir = \"../aclImdb/test\"\n",
    "\n",
    "# 读取数据\n",
    "def read_reviews_from_dir(directory):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for label_dir, label in zip([\"pos\", \"neg\"], [1, 0]):\n",
    "        label_dir_path = os.path.join(directory, label_dir)\n",
    "        for filename in os.listdir(label_dir_path):\n",
    "            with open(os.path.join(label_dir_path, filename), 'r', encoding='utf-8') as file:\n",
    "                reviews.append(file.read())\n",
    "                labels.append(label)\n",
    "    return reviews, labels\n",
    "\n",
    "# 加载训练和测试数据\n",
    "train_reviews, train_labels = read_reviews_from_dir(train_dir)\n",
    "test_reviews, test_labels = read_reviews_from_dir(test_dir)\n",
    "\n",
    "# 将数据转换为 Hugging Face Dataset 格式\n",
    "train_data = Dataset.from_dict({\"text\": train_reviews, \"label\": train_labels})\n",
    "test_data = Dataset.from_dict({\"text\": test_reviews, \"label\": test_labels})\n",
    "\n",
    "# 创建 DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_data,\n",
    "    'test': test_data\n",
    "})\n",
    "\n",
    "# 加载 BERT 模型和分词器\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 加载 BERT 模型\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=5).to(device)  # 修改为5个标签\n",
    "\n",
    "# 数据预处理函数\n",
    "def preprocess_function(examples):\n",
    "    # 标签从 0/1 -> 1/5 映射\n",
    "    label_mapping = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5}\n",
    "    examples[\"label\"] = [label_mapping[label] for label in examples[\"label\"]]\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# 对训练和测试数据进行预处理\n",
    "dataset = dataset.map(preprocess_function, batched=True)\n",
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "print(accelerate.__version__)  # 确保 >= 0.26.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0+cu126\n",
      "Accelerate version: Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9375' max='9375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9375/9375 3:25:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.293100</td>\n",
       "      <td>0.296097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>0.345305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.343130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 08:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3431304693222046,\n",
       " 'eval_runtime': 507.8478,\n",
       " 'eval_samples_per_second': 49.227,\n",
       " 'eval_steps_per_second': 6.153,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers  import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Accelerate version: {Accelerator().state}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "# 创建 Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # 模型\n",
    "    args=training_args,                  # 训练参数\n",
    "    train_dataset=dataset['train'],         # 训练数据\n",
    "    eval_dataset=dataset['test'],           # 验证数据\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()\n",
    "\n",
    "# 训练结束后可以进行模型评估\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型已保存至: ./saved_model\n",
      "✅ 测试集准确率: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# =======================\n",
    "# ✅ 保存模型\n",
    "# =======================\n",
    "model_save_path = \"./saved_model\"\n",
    "trainer.save_model(model_save_path)  # 保存模型和配置文件\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(\"✅ 模型已保存至:\", model_save_path)\n",
    "\n",
    "# =======================\n",
    "# ✅ 测试集推理\n",
    "# =======================\n",
    "# 加载保存的模型\n",
    "model = BertForSequenceClassification.from_pretrained(model_save_path).to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "# 单个样本预测函数\n",
    "def predict_sentiment(text):\n",
    "    model.eval()  # 切换为评估模式\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "    return predicted_class\n",
    "\n",
    "# 批量预测\n",
    "def evaluate_on_test_set():\n",
    "    correct = 0\n",
    "    total = len(test_reviews)\n",
    "    predictions = []\n",
    "\n",
    "    for text, label in zip(test_reviews, test_labels):\n",
    "        pred = predict_sentiment(text)\n",
    "        predictions.append(pred)\n",
    "        # 模型预测的label范围是1-5, 映射回0(负面)/1(正面)\n",
    "        mapped_pred = 0 if pred <= 2 else 1  # 1,2 -> 0 (负面)；4,5 -> 1 (正面)\n",
    "        if mapped_pred == label:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(\"✅ 测试集准确率: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# 在测试集上评估\n",
    "evaluate_on_test_set()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
