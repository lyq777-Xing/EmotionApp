{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch transformers datasets  scikit-learn\n",
    "# pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔧 Step 1: 数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' texts = [\"我今天很开心\", \"心情有点低落\", \"天气不错，但工作好累\"]\\nlabels = [\"快乐\", \"悲伤\", \"中立\"]\\n\\n# 标签编码\\nlabel_encoder = LabelEncoder()\\nencoded_labels = label_encoder.fit_transform(labels)\\n\\n# 转化为Hugging Face格式\\ndataset = Dataset.from_dict({\"text\": texts, \"label\": encoded_labels}) '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" texts = [\"我今天很开心\", \"心情有点低落\", \"天气不错，但工作好累\"]\n",
    "labels = [\"快乐\", \"悲伤\", \"中立\"]\n",
    "\n",
    "# 标签编码\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# 转化为Hugging Face格式\n",
    "dataset = Dataset.from_dict({\"text\": texts, \"label\": encoded_labels}) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChnSentiCorp 常用的中文情感分类数据集(电商产品向)\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"clue\", \"tnews\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 392702/392702 [00:00<00:00, 1498736.64 examples/s]\n",
      "Generating test split: 100%|██████████| 5010/5010 [00:00<00:00, 1269158.85 examples/s]\n",
      "Generating validation split: 100%|██████████| 2490/2490 [00:00<00:00, 698489.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': '从 概念 上 看 , 奶油 收入 有 两 个 基本 方面 产品 和 地理 .', 'hypothesis': '产品 和 地理 是 什么 使 奶油 抹 霜 工作 .', 'label': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#XNLI (Cross-lingual NLI Corpus)数据集\n",
    "dataset = load_dataset(\"xnli\", \"zh\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': ['从 概念 上 看 , 奶油 收入 有 两 个 基本 方面 产品 和 地理 .', '你 知道 在 这个 季节 , 我 猜 在 你 的 水平 你 把 他们 丢到 下 一个 水平 , 如果 他们 决定 召回 的 家长 队 , 勇士 队 决定 打电话 召回 一个 家伙 从 三 个 a , 然后 一个 双人 上 去. 取代 他 和 一个 男人 去 取代 他', '我们 的 一个 号码 会 非常 详细 地 执行 你 的 指示', '你 怎么 知道 的 ? 所有 这些 都 是 他们 的 信息 .', '是 啊 , 我 告诉 你 , 如果 你 去 买 一些 网球鞋 , 我 可以 看到 为什么 现在 你 知道 他们 是 起床 在 百 美元 范围 .'], 'hypothesis': ['产品 和 地理 是 什么 使 奶油 抹 霜 工作 .', '如果 人们 记得 的 话 , 你 就 会 把 事情 弄 丢 了 .', '我 团队 的 一个 成员 将 非常 精确 地 执行 你 的 命令', '这些 信息 属于 他们 .', '网球鞋 有 一 系列 的 价格 .'], 'label': [1, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 🔧 Step 2: 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"bert-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 🔧 Step 3: 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 392702/392702 [02:30<00:00, 2611.44 examples/s]\n",
      "Map: 100%|██████████| 5010/5010 [00:01<00:00, 2976.62 examples/s]\n",
      "Map: 100%|██████████| 2490/2490 [00:00<00:00, 3013.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_data(example):\n",
    "    encoding = tokenizer(example['premise'], padding='max_length', truncation=True, max_length=128)\n",
    "    encoding['label'] = example['label']\n",
    "    return encoding\n",
    "\n",
    "dataset = dataset.map(preprocess_data)\n",
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔧 Step 4: 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='147264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   146/147264 08:21 < 142:25:07, 0.29 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 🔧 Step 5: 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('悲伤')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.str_('悲伤')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.str_('悲伤')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.str_('悲伤')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_label = torch.argmax(logits, dim=1).item()\n",
    "    return label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "# 测试推理\n",
    "display(predict(\"今天真是开心的一天！\"))\n",
    "display(predict(\"我有点难过\"))\n",
    "display(predict(\"心情很差\"))\n",
    "display(predict(\"天气很好，但我很累\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
