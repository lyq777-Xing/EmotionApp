{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch transformers datasets  scikit-learn\n",
    "# pip install transformers[torch]\n",
    "\n",
    "#åœ¨ubantuä¸Šè¿è¡Œ\n",
    "# jupyter nbconvert --to html --execute test.ipynb --stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”§ Step 1: æ•°æ®é›†å‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' texts = [\"æˆ‘ä»Šå¤©å¾ˆå¼€å¿ƒ\", \"å¿ƒæƒ…æœ‰ç‚¹ä½è½\", \"å¤©æ°”ä¸é”™ï¼Œä½†å·¥ä½œå¥½ç´¯\"]\\nlabels = [\"å¿«ä¹\", \"æ‚²ä¼¤\", \"ä¸­ç«‹\"]\\n\\n# æ ‡ç­¾ç¼–ç \\nlabel_encoder = LabelEncoder()\\nencoded_labels = label_encoder.fit_transform(labels)\\n\\n# è½¬åŒ–ä¸ºHugging Faceæ ¼å¼\\ndataset = Dataset.from_dict({\"text\": texts, \"label\": encoded_labels}) '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" texts = [\"æˆ‘ä»Šå¤©å¾ˆå¼€å¿ƒ\", \"å¿ƒæƒ…æœ‰ç‚¹ä½è½\", \"å¤©æ°”ä¸é”™ï¼Œä½†å·¥ä½œå¥½ç´¯\"]\n",
    "labels = [\"å¿«ä¹\", \"æ‚²ä¼¤\", \"ä¸­ç«‹\"]\n",
    "\n",
    "# æ ‡ç­¾ç¼–ç \n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# è½¬åŒ–ä¸ºHugging Faceæ ¼å¼\n",
    "dataset = Dataset.from_dict({\"text\": texts, \"label\": encoded_labels}) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #ChnSentiCorp å¸¸ç”¨çš„ä¸­æ–‡æƒ…æ„Ÿåˆ†ç±»æ•°æ®é›†(ç”µå•†äº§å“å‘)\\nfrom datasets import load_dataset\\ndataset = load_dataset(\"clue\", \"tnews\")\\nprint(dataset[\\'train\\'][0]) '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #ChnSentiCorp å¸¸ç”¨çš„ä¸­æ–‡æƒ…æ„Ÿåˆ†ç±»æ•°æ®é›†(ç”µå•†äº§å“å‘)\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"clue\", \"tnews\")\n",
    "print(dataset['train'][0]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': 'ä» æ¦‚å¿µ ä¸Š çœ‹ , å¥¶æ²¹ æ”¶å…¥ æœ‰ ä¸¤ ä¸ª åŸºæœ¬ æ–¹é¢ äº§å“ å’Œ åœ°ç† .', 'hypothesis': 'äº§å“ å’Œ åœ°ç† æ˜¯ ä»€ä¹ˆ ä½¿ å¥¶æ²¹ æŠ¹ éœœ å·¥ä½œ .', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "#XNLI (Cross-lingual NLI Corpus)æ•°æ®é›†\n",
    "dataset = load_dataset(\"xnli\", \"zh\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': ['ä» æ¦‚å¿µ ä¸Š çœ‹ , å¥¶æ²¹ æ”¶å…¥ æœ‰ ä¸¤ ä¸ª åŸºæœ¬ æ–¹é¢ äº§å“ å’Œ åœ°ç† .', 'ä½  çŸ¥é“ åœ¨ è¿™ä¸ª å­£èŠ‚ , æˆ‘ çŒœ åœ¨ ä½  çš„ æ°´å¹³ ä½  æŠŠ ä»–ä»¬ ä¸¢åˆ° ä¸‹ ä¸€ä¸ª æ°´å¹³ , å¦‚æœ ä»–ä»¬ å†³å®š å¬å› çš„ å®¶é•¿ é˜Ÿ , å‹‡å£« é˜Ÿ å†³å®š æ‰“ç”µè¯ å¬å› ä¸€ä¸ª å®¶ä¼™ ä» ä¸‰ ä¸ª a , ç„¶å ä¸€ä¸ª åŒäºº ä¸Š å». å–ä»£ ä»– å’Œ ä¸€ä¸ª ç”·äºº å» å–ä»£ ä»–', 'æˆ‘ä»¬ çš„ ä¸€ä¸ª å·ç  ä¼š éå¸¸ è¯¦ç»† åœ° æ‰§è¡Œ ä½  çš„ æŒ‡ç¤º', 'ä½  æ€ä¹ˆ çŸ¥é“ çš„ ? æ‰€æœ‰ è¿™äº› éƒ½ æ˜¯ ä»–ä»¬ çš„ ä¿¡æ¯ .', 'æ˜¯ å•Š , æˆ‘ å‘Šè¯‰ ä½  , å¦‚æœ ä½  å» ä¹° ä¸€äº› ç½‘çƒé‹ , æˆ‘ å¯ä»¥ çœ‹åˆ° ä¸ºä»€ä¹ˆ ç°åœ¨ ä½  çŸ¥é“ ä»–ä»¬ æ˜¯ èµ·åºŠ åœ¨ ç™¾ ç¾å…ƒ èŒƒå›´ .'], 'hypothesis': ['äº§å“ å’Œ åœ°ç† æ˜¯ ä»€ä¹ˆ ä½¿ å¥¶æ²¹ æŠ¹ éœœ å·¥ä½œ .', 'å¦‚æœ äººä»¬ è®°å¾— çš„ è¯ , ä½  å°± ä¼š æŠŠ äº‹æƒ… å¼„ ä¸¢ äº† .', 'æˆ‘ å›¢é˜Ÿ çš„ ä¸€ä¸ª æˆå‘˜ å°† éå¸¸ ç²¾ç¡® åœ° æ‰§è¡Œ ä½  çš„ å‘½ä»¤', 'è¿™äº› ä¿¡æ¯ å±äº ä»–ä»¬ .', 'ç½‘çƒé‹ æœ‰ ä¸€ ç³»åˆ— çš„ ä»·æ ¼ .'], 'label': [1, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ”§ Step 2: åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#ç¡®è®¤GPUæ˜¯å¦å¯ç”¨ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨CPU\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device=torch.device('cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"bert-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ”§ Step 3: æ•°æ®é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(example):\n",
    "    encoding = tokenizer(example['premise'], padding='max_length', truncation=True, max_length=128)\n",
    "    encoding['label'] = example['label']\n",
    "    return encoding\n",
    "\n",
    "dataset = dataset.map(preprocess_data)\n",
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”§ Step 4: æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      1\u001b[39m training_args = TrainingArguments(\n\u001b[32m      2\u001b[39m     output_dir=\u001b[33m'\u001b[39m\u001b[33m./results\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m     num_train_epochs=\u001b[32m3\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     save_strategy=\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m trainer = Trainer(\n\u001b[32m     11\u001b[39m     model=model,\n\u001b[32m     12\u001b[39m     args=training_args,\n\u001b[32m     13\u001b[39m     train_dataset=dataset[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m:\u001b[32m100\u001b[39m],\n\u001b[32m     14\u001b[39m     eval_dataset=dataset\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2508\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2506\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2507\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2508\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2509\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[32m   2510\u001b[39m     step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\.venv\\Lib\\site-packages\\transformers\\trainer.py:5224\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5222\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5223\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5224\u001b[39m         batch_samples += [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m   5225\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5226\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\.venv\\Lib\\site-packages\\accelerate\\data_loader.py:566\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     current_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\demo\\EmotionApp\\backend\\EmotionAppBackend\\Algorithm\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ”§ Step 5: æ¨¡å‹æ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('æ‚²ä¼¤')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.str_('æ‚²ä¼¤')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.str_('æ‚²ä¼¤')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.str_('æ‚²ä¼¤')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_label = torch.argmax(logits, dim=1).item()\n",
    "    return label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "# æµ‹è¯•æ¨ç†\n",
    "display(predict(\"ä»Šå¤©çœŸæ˜¯å¼€å¿ƒçš„ä¸€å¤©ï¼\"))\n",
    "display(predict(\"æˆ‘æœ‰ç‚¹éš¾è¿‡\"))\n",
    "display(predict(\"å¿ƒæƒ…å¾ˆå·®\"))\n",
    "display(predict(\"å¤©æ°”å¾ˆå¥½ï¼Œä½†æˆ‘å¾ˆç´¯\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
